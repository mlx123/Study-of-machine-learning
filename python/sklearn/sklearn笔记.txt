1.sklearn.preprocessing数据预处理
标准化standardization:  减去均值除以方差
                        把数据标准化在某一指定的范围
                         缩放稀疏数据
非线性变换：把他正变换到已知的范围或分布中，如变换为高斯分布
归一化是将单个样本缩放为具有单位范数的过程。
其他

2.数据分割
model_selection.train_test_split 可以随机将数据分割为训练集和测试集



-----------------------模型类----------------
1.sklearn.linear_model  产生线性模型，如贝叶斯回归，逻辑回归，并用模型取训练数据
      model.fit()#用数据训练模型的参数   model.predict()#用训练好的模型去预测  其他，如逻辑回归预测出概率(lr.predict_proba(X_test_undersample.values))


---------模型的validata--------
交叉验证：
    数据分割model_selection.KFold([n_splits, shuffle, …]) 把数据分成K份用于交叉验证 用法: fold = KFold(5,shuffle=False)#给定要分割的份数  for indices in fold.split(Arraydata)#根据Arraydata的长度和药分割的份数给出分割后的样本训练集的索引indices[0]和验证集的索引indices[1]
	         cross_val_score 得到交叉验证的的得分
			 
	-------模型的评估指标----
	分类指标：confusion_matrix recall_score f1_score  classification_report(得到一个主要参数的报告)
	
	
sklearn.grid_search.GridSearchCV  遍历模型的超参数的不同组合来找到最佳的超参数
RandomizedSearchCV 寻找最佳参数

4.sklearn中将文本字符串向量化
4.1 根据词频向量化
from sklearn.feature_extraction.text import CountVectorizer
texts=["dog cat fish","dog cat cat","fish bird", 'bird']
cv = CountVectorizer()
cv_fit=cv.fit_transform(texts)
print(cv.get_feature_names())
print(cv_fit.toarray())

4.2用tf-idf将一段话向量化
from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer = TfidfVectorizer(analyzer='word', max_features=4000,  lowercase = False)
vectorizer.fit(words)
vectorizer.transform(words)